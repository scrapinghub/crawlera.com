{% extends "page.html" %}

{% block body_class %}about{% endblock %}

{% block subnav-about %} class="active"{% endblock %}
 
{% block page-title %}About Us{% endblock %}
 
{% block page-content %}
<div class="row">
  <div class="large-10 columns">
    <h2>Overview</h2>
<p>ProxyHub provides an HTTP proxy, with a pool of rotating IPs, designed specifically for scraping purposes. Although it provides a standard HTTP proxy interface it does a lot more internally, like throttling access to domains by introducing delays and discarding IPs from the pool when they get banned or have other problems. As a scraping user, you no longer have to worry about tinkering with download delays, concurrent requests, user agents, cookies or referrers to avoid getting banned from sites, you just configure the proxy and fire up your crawler of choice and start scraping.
    <h2>Examples</h2>

    <h3>cURL</h3>
    <p>ProxyHub provides a standard HTTP proxy interface so you can use it with any software that supports them.
Here is an example using ProxyHub with curl to download <a href="http://scrapinghub.com">http://scrapinghub.com</a>:
    
    <div class="panel">
      curl -x proxy.scrapinghub.com:8010 -U USER:PASS http://scrapinghub.com
    </div>

    <h3>Command-line tools</h3>
    <p>Several Unix commands (like wget and curl) and applications (including Scrapy) support the http_proxy environment variable to configure the HTTP proxy to use.
You can configure before running your command with:
    <div class="panel">
      export http_proxy=http://USER:PASS@proxy.scrapinghub.com:8010
    </div>

    <h3>Scrapy</h3>
    <p>To use ProxyHub with Scrapy you could just set the http_proxy
    environment setting (as explained in the previous
    section). However, if you need more functionality (like
    configuring which spiders to send through the proxy) you can use
    the HubProxyMiddleware, provided in the scrapylib project.
    
    <p>Download the scrapylib project, and enable the middleware by
    adding this to your Scrapy settings:
    <div class="panel">
      DOWNLOADER_MIDDLEWARES = {'scrapylib.hubproxy.HubProxyMiddleware': 600}
    </div>
  </div>
  </div class="large-4 columns">
  
  </div>
</div>
<h1>About Us</h1>

<div class="person">
  <img class="column" width="124" height="150" src="{{ MEDIA_URL }}images/people/pablo.jpg" alt="Pablo Hoffman photo" />
  <p><b>Pablo Hoffman</b> - Founder</p>
  <p>Pablo has been working on a wide range of
  web scraping projects since 2007. He's the lead developer of <a class="external"
  href="http://scrapy.org">Scrapy</a>, an open source screen scraping framework
  for Python. He also founded <a class="external" href="http://insophia.com">Insophia</a>, a
  company that provides screen scraping and system administration help to
  bootstrap your startup.</p>
</div>
 
<hr class="space" />

<div class="person">
  <img class="column" width="124" height="150" src="{{ MEDIA_URL }}images/people/shane.jpg" />
  <p><b>Shane Evans</b> - Founder</p>
  <p>Shane has been involved in startups since joining
  lastminute.com in 1999, where he led development of the most critical projects
  there for many years. Since that time he has been part of the founding team for
  a few companies, always seeking out interesting technical challenges. He was
  introduced to web crawling when leading development of the search systems at
  mydeco.com. Some of the web crawling code he wrote at that time was open
  sourced as the <a class="external" href="http://scrapy.org">Scrapy</a> project.</p>
</div>

{% endblock %}
