---
layout: default
---

<div class="body clearfix">
  <div class="white-area">
    <h3>What is Crawlera?</h3>

    <p>Crawlera is a smart HTTP/HTTPS downloader designed specifically for
    web crawling and scraping. It routes requests through a pool of IPs,
    throttling access by introducing delays and discarding IPs from the pool
    when they get banned from certain domains, or have other problems.

    As a scraping user, you no longer have to worry about tinkering with
    download delays, concurrent requests, user agents, cookies or referrers to
    avoid getting banned, you just use Crawlera to download pages instead.

    Some plans provide a standard HTTP proxy API, so you can configure it in
    your crawler of choice and start crawling.
    <br />

    <h3>How does it work?</h3>
    <p>Crawlera distributes requests among many internal nodes, using a
    proprietary algorithm to minimize the risks of getting banned, by throttling
    requests sent to sites from each internal node. If, for whatever reason, any
    node gets banned, Crawlera will blacklist it and avoid using it for future
    requests to that domain.
    </p>

    <p>Banned requests typically return a non-200 response (like 403 or 503), or
    redirect to a captcha page. These responses are detected by Crawlera and the
    requests are automatically retried from another (clean) node. This is just a
    very brief introduction of what happens inside Crawlera, the details are more
    sophisticated.</p>

    <p>All this logic happens inside Crawlera and the user doesn't have to worry
    about it. The user receives a clean response or a 503 error if all internal
    nodes are blacklisted (which usually doesn't happen, except for very popular
    domains). Only successful downloads are charged.</p>

    <p>If you need more bandwidth, you can contact support and reserve exclusive
    nodes to increase the capacity, or supply your own nodes (as HTTP proxies) and
    use them from Crawlers to benefit from its smart downloading mechanism.

    See <a href="{{ site.baseurl }}/pricing">Pricing</a> for more details.
    </p>

    <h3>Example</h3>
    <p>Using Crawlera is as easy as running following command:
    <pre>  curl -x paygo.crawlera.com:8010 -U <API key>: http://www.food.com/</pre>
    <br /><br />
    <div style="text-align: center">
      <a class="redirect-button" href="http://scrapinghub.com/crawlera"><input type="submit" value="Learn More  "></a>
      <div class="button-divider"/>
        <a class="redirect-button" href="http://scrapinghub.com/crawlera-signup"><input type="submit" value="Sign Up  "></a>
      </div>
      <br />
      <br />
      <br />
    </div>
  </div>
